{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "tz = pytz.timezone('America/Mexico_City')\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import glob\n",
    "import distutils.dir_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista = pd.read_csv(\"colima.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lista.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_drivers = l.toolsdriver_partner_uuid.value_counts().to_frame().reset_index().rename(columns={'toolsdriver_partner_uuid': 'count_of_drivers', 'index': 'toolsdriver_partner_uuid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full = pd.merge(l, all_drivers, on='toolsdriver_partner_uuid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = full.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_files = ['uuid', 'format', 'vehicle_owner', 'plate', 'driver', 'document']\n",
    "\n",
    "#Driver docs\n",
    "#ine_driver = l[['toolsdocument_identificacion_conductor', 'formato_identificacion_conductor', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "lic_driver = l[['toolsdocument_licencia_conducir_conductor', 'formato_licencia_conducir_conductor', 'nombre_propietario', 'placa', 'nombre_conductor']]\n",
    "#cnap_driver = l[['toolsdocument_carta_no_antecedentes_conductor', 'formato_carta_no_antecedentes_conductor', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "#circ_files = l[['circ_uuid', 'circ_format']]\n",
    "\n",
    "\n",
    "#Partner docs\n",
    "#ine_partner = l[['toolsdocument_identificacion_socio', 'formato_identificacion_socio', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "#lic_partner = l[['toolsdocument_licencia_conducir_socio', 'formato_licencia_conducir_socio', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "#cnap_partner = l[['toolsdocument_carta_no_antecedentes_socio', 'formato_carta_no_antecedentes_socio', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "\n",
    "\n",
    "#Vehicle docs\n",
    "circulacion = l[['toolsdocument_tarjeta_circulacion', 'formato_tarjeta_circulacion', 'nombre_propietario', 'placa', 'nombre_conductor']]\n",
    "#seguro = l[['toolsdocument_seguro_vehicular', 'formato_seguro_vehicular', 'nombre_completo_socio', 'placa', 'nombre_completo_conductor']]\n",
    "\n",
    "\n",
    "#Assign document type\n",
    "#ine_driver = ine_driver.assign(document_type = 'ine_driver')\n",
    "lic_driver = lic_driver.assign(document_type = 'lic_driver')\n",
    "#cnap_driver = cnap_driver.assign(document_type = 'cnap_driver')\n",
    "#ine_partner = ine_partner.assign(document_type = 'ine_partner')\n",
    "#lic_partner = lic_partner.assign(document_type = 'lic_partner')\n",
    "#cnap_partner = cnap_partner.assign(document_type = 'cnap_partner')\n",
    "circulacion = circulacion.assign(document_type = 'circulacion')\n",
    "#seguro = seguro.assign(document_type = 'seguro')\n",
    "\n",
    "\n",
    "#Rename columns\n",
    "#ine_driver.columns = col_files\n",
    "lic_driver.columns = col_files\n",
    "#cnap_driver.columns = col_files\n",
    "#ine_partner.columns = col_files\n",
    "#lic_partner.columns = col_files\n",
    "#cnap_partner.columns = col_files\n",
    "circulacion.columns = col_files\n",
    "#seguro.columns = col_files\n",
    "#circ_files.columns = col_files\n",
    "\n",
    "d = pd.concat([lic_driver, circulacion])\n",
    "#d = pd.concat([ine_files, lic_files, cnap_files, circ_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workfolder will be: Colima_2021-03-09\n"
     ]
    }
   ],
   "source": [
    "workname = 'Colima_{:%Y-%m-%d}'.format(datetime.now(tz))\n",
    "print('Workfolder will be: {}'.format(workname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created work Colima_2021-03-09\n"
     ]
    }
   ],
   "source": [
    "# create work folder\n",
    "distutils.dir_util.mkpath('output_uber_s3/{}/'.format(workname))\n",
    "distutils.dir_util.mkpath('input_uber_s3/{}/'.format(workname))\n",
    "distutils.dir_util.mkpath('reports/{}/'.format(workname))\n",
    "print('Created work {}'.format(workname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk list of Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = d.copy()\n",
    "f = q.copy()\n",
    "\n",
    "q = q.set_index('uuid')\n",
    "q = q.sort_index()\n",
    "\n",
    "f = f[['uuid', 'format']]\n",
    "f = f[~f.uuid.duplicated(keep='first')]\n",
    "f = f.dropna()\n",
    "\n",
    "r = list(range(0,len(f), 30000))\n",
    "r.append(len(f))\n",
    "\n",
    "for i in range(len(r) -1):\n",
    "    f[r[i]:r[i+1]].to_csv('input_uber_s3/{}/colima_csv_chunk_{}.csv'.format(workname, i), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go to Alexandria and use the files generated under the `input_uber_s3` folder to generate the S3 links to downlaod the documents.\n",
    "\n",
    "\n",
    "## Ingest S3 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digest_list = glob.glob('output_uber_s3/{}/*.csv'.format(workname))\n",
    "\n",
    "list_ = []\n",
    "for i in digest_list:\n",
    "    df = pd.read_csv(i)\n",
    "    list_.append(df)\n",
    "li = pd.concat(list_)\n",
    "li = li[~li.UUID.duplicated(keep='first')]\n",
    "\n",
    "len(q[(~q.index.isin(li.UUID))]) #Â number of files not found in the full list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ll = li.to_dict(orient='records') \n",
    "\n",
    "for x,i in enumerate(ll):\n",
    "    p = q.loc[i['UUID']]\n",
    "    if isinstance(p, pd.core.series.Series):\n",
    "        ll[x]['files'] = [p.to_dict()]\n",
    "    else:\n",
    "        ll[x]['files'] = p.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_ = 'reports/{}/colima_{:%Y-%m-%d}.pickle'.format(workname, datetime.now(tz))\n",
    "pi = pd.to_pickle(ll, pickle_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download!\n",
    "\n",
    "Now, use the script `fetcher.py` to download the files to your computer (or hard drive). You will need to:\n",
    "- Put the script in the same folder as the pickle file\n",
    "- Open the Terminal and run the script. `python fetcher.py <pickle> <download folder>`\n",
    "    - Example: `python fetcher.py the_pickle.p /Volumes/HDRIVE/Regulatory/GDL`\n",
    "    - Hint: To get the path of folder, navigate to the folder and use the `pwd` to print the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = lista.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldic = d.to_dict(orient='records')\n",
    "for e in eldic:\n",
    "    e['dia'] = e['curp_conductor'][8:10]\n",
    "    e['mes'] = e['curp_conductor'][6:8]\n",
    "    if '00' in e['curp_conductor'][4:6] or '01' in e['curp_conductor'][4:6]:\n",
    "        e['anio'] = '20' + e['curp_conductor'][4:6]\n",
    "    else:\n",
    "        e['anio'] = '19' + e['curp_conductor'][4:6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in eldic:\n",
    "    spl = e['nombre_conductor'].split(' ')\n",
    "    if len(spl) == 3:\n",
    "        e['nombre'] = spl[0]\n",
    "        e['apellido_paterno'] = spl[1]\n",
    "        e['apellido_materno'] = spl[2]\n",
    "    elif len(spl) == 4:\n",
    "        e['nombre'] = spl[0] + ' ' + spl[1]\n",
    "        e['apellido_paterno'] = spl[2]\n",
    "        e['apellido_materno'] = spl[3]\n",
    "    else:\n",
    "        e['nombre'] = 'Sacalo manual papus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.consisa.com.mx/rfc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 185/185 [02:16<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "dd = []\n",
    "\n",
    "with tqdm.tqdm(total=len(eldic)) as bar:\n",
    "    for e in eldic:\n",
    "        if e['nombre'] == 'Sacalo manual papus':\n",
    "            rfc = 'Sacalo manual mi ninio'\n",
    "        else:\n",
    "            try:\n",
    "                payload = {'strNombre': e['nombre'],\n",
    "                           'strPrimerApellido': e['apellido_paterno'],\n",
    "                           'strSegundoApellido': e['apellido_materno'],\n",
    "                           'strdia': e['dia'],\n",
    "                           'strmes': e['mes'],\n",
    "                           'stranio': e['anio'],\n",
    "                           'task': 'calcular.rfc'\n",
    "                          }\n",
    "\n",
    "                req = requests.post(url, data=payload)\n",
    "                soup = BeautifulSoup(req.text, 'html.parser')\n",
    "                rfc = soup.find_all('strong')[4].find_next().string[1:14]\n",
    "            \n",
    "            except IndexError:\n",
    "                rfc = 'Sacalo manual mi ninio'\n",
    "\n",
    "        dec = {'toolsvehicle_vehicle_uuid': e['toolsvehicle_vehicle_uuid'],\n",
    "               'placa': e['placa'], \n",
    "               'numero_de_serie': e['numero_de_serie'], \n",
    "               'marca': e['marca'],\n",
    "               'submarca': e['submarca'],\n",
    "               'modelo': e['modelo'],\n",
    "               'nombre_propietario': e['nombre_propietario'],\n",
    "               'nombre_conductor': e['nombre_conductor'],\n",
    "               'numero_licencia_conductor': e['numero_licencia_conductor'],\n",
    "               'rfc_conductor': rfc\n",
    "              }\n",
    "        dd.append(dec)\n",
    "        bar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.replace('SÃ¡calo manual mi ninio', 'Sacalo manual mi ninio', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[['toolsvehicle_vehicle_uuid', 'placa', 'numero_de_serie', 'marca', 'submarca', 'modelo', \n",
    "       'nombre_propietario', 'nombre_conductor', 'numero_licencia_conductor', \n",
    "       'rfc_conductor'\n",
    "      ]].to_excel('reports/{}/lista_de_conductores_uber_colima_{:%Y-%m-%d}.xlsx'.format(workname, datetime.now(tz)),encoding='UTF-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
